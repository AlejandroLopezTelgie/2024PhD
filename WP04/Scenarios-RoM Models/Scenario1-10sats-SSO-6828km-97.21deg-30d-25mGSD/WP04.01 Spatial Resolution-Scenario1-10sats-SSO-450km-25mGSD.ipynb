{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f266aa02",
   "metadata": {},
   "source": [
    "# WP04  RoM Models\n",
    "Goal of this WP is to provide EO payload sizing rough order of magnitude (RoM) sizing relations to adressed two main questions\n",
    "Can we \"see/distinguish\" the phenomenon/thing of interest? Which is answered by the EO resolution metrics\n",
    "Can we download the data on time? Which is to be answered with the input of orbital simulation yielding contact imes with gorund segment (ground stations) and the data generation as a funtion or orbit over area of interest (AoI) at nadir \\times a data rate (part two of this code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf81cb8",
   "metadata": {},
   "source": [
    "@AL Update IPO keep I&O remove controls\n",
    "![PhD IPO Diagrams for process.png](../Figs/PhD%20IPO%20Diagrams%20for%20process.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969ba9f",
   "metadata": {},
   "source": [
    "## WP04.01 Earth Observation Payload Sizing relations (Context i.e. what is feasible) \n",
    "Based on [Valenzuela and Reyes 2019] the metrics for resolution $R$ where implemented in the following phase\n",
    "\n",
    "This is done to size the payload spatial resolution based on analogy to other missions and provide initial values for the mission analysis by constraining the \"phisically\" feasible values (i.e. the finner spatial resolution achievable given the boudar/constrains of the CubeSat)\n",
    "\n",
    "Note that in the discussion with small satellite developers the cosntrains of te CubeSat standar in terms of its dimenssiones where mentiones as rationale for moving to microsatelites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b6351f",
   "metadata": {},
   "source": [
    "### INPUT: Resolution definition\n",
    "\n",
    "- $ p $ IS DETECTOR LEVEL PITCH\n",
    "- $ f $ IS FOCAL LENGTH\n",
    "- $ LAMBD $ IS $ \\lambda $, AVERAGE WAVELENGTH\n",
    "- $ H $ IS ALTITUDE \n",
    "\n",
    "Values are taken from TABLE 3-1 Lopez & dos Santos 2020 WETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a677c35-f418-46bf-9057-8f645f593c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "## INITIALIZATION OF VARIABLES\n",
    "# Defines vectors with all the values on Lopez & dos Santos 2020 to calculate the differente spatial resolution metrics by Valenzuela & Reyes 2019\n",
    "\n",
    "p=np.array([7.4e-6, 5.5e-6, 5.5e-6, 5.5e-6])\n",
    "f=np.array([3.2, 0.9, 0.9, 0.3])\n",
    "lambd=np.array([5.5e-7, 5.5e-7, 5.5e-7, 5.5e-7])\n",
    "H=np.array([6.2e5, 6e5, 4e5, 4e5])\n",
    "D=np.array([0.2, 0.09, 0.09, 0.09])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625e9ab",
   "metadata": {},
   "source": [
    "### PROCESS: Earth observation resolution relationships \n",
    "Relationships adapted from [Valenzuela & Reyes 2019]\n",
    "- Ground Sample Distance (GSD)\n",
    "- Raleigh Difraction Limit (RDL)\n",
    "- Ground Spot Size (GSS)\n",
    "- Optical factor (Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae0d1a",
   "metadata": {},
   "source": [
    "$$\n",
    "R_{GSD}= p\\frac{H}{f} [m]\\\\\n",
    "\n",
    "R_{RDL}=1.22\\frac{\\lambda H}{D} [m]\\\\\n",
    " \n",
    "R_{GSS}= \\lambda\\frac{H}{D} [m]\\\\\n",
    "\n",
    "Q= \\lambda\\frac{f}{Dp} [-]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ad57be-a84c-445a-9ef4-eafe131bd158",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EQUATIONS\n",
    "\n",
    "R_GSD= p*H/f # [m] Ground Sample Distance\n",
    "\n",
    "R_RDL=1.22*lambd*H/D # Raleigh Difraction Limit [m]\n",
    "\n",
    "R_GSS= lambd*H/D # Ground Spot Size [m]\n",
    "\n",
    "Q= lambd*f/(D*p) # Quality Factor [-]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "002d2d38-90d7-4fe5-87d4-bfd38f343915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Satellite</th>\n",
       "      <th>Pixel pitch, p [m]</th>\n",
       "      <th>Satellite Altitude, H [m]</th>\n",
       "      <th>Instrumental Focal Length, f [m]</th>\n",
       "      <th>Ground Sample Distance, R_GSD [m]</th>\n",
       "      <th>Average Wavelength, $\\lambda$ [m]</th>\n",
       "      <th>Diameter, D [m]</th>\n",
       "      <th>Rayleigh Difraction Limit, R_RDL [m]</th>\n",
       "      <th>Ground Spot Size, R_GSS [m]</th>\n",
       "      <th>Optical Factor,  Q [-]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SSOT_SSO</td>\n",
       "      <td>7.40e-06</td>\n",
       "      <td>6.20e+05</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.43</td>\n",
       "      <td>5.50e-07</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3U_Dove_SSO</td>\n",
       "      <td>5.50e-06</td>\n",
       "      <td>6.00e+05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.67</td>\n",
       "      <td>5.50e-07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.67</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3U_Dove_ISS</td>\n",
       "      <td>5.50e-06</td>\n",
       "      <td>4.00e+05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.44</td>\n",
       "      <td>5.50e-07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2.98</td>\n",
       "      <td>2.44</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1U_Cubesat_ISS</td>\n",
       "      <td>5.50e-06</td>\n",
       "      <td>4.00e+05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.33</td>\n",
       "      <td>5.50e-07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2.98</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Satellite Pixel pitch, p [m] Satellite Altitude, H [m]  \\\n",
       "0        SSOT_SSO           7.40e-06                  6.20e+05   \n",
       "1     3U_Dove_SSO           5.50e-06                  6.00e+05   \n",
       "2     3U_Dove_ISS           5.50e-06                  4.00e+05   \n",
       "3  1U_Cubesat_ISS           5.50e-06                  4.00e+05   \n",
       "\n",
       "   Instrumental Focal Length, f [m] Ground Sample Distance, R_GSD [m]  \\\n",
       "0                               3.2                              1.43   \n",
       "1                               0.9                              3.67   \n",
       "2                               0.9                              2.44   \n",
       "3                               0.3                              7.33   \n",
       "\n",
       "  Average Wavelength, $\\lambda$ [m]  Diameter, D [m]  \\\n",
       "0                          5.50e-07             0.20   \n",
       "1                          5.50e-07             0.09   \n",
       "2                          5.50e-07             0.09   \n",
       "3                          5.50e-07             0.09   \n",
       "\n",
       "  Rayleigh Difraction Limit, R_RDL [m] Ground Spot Size, R_GSS [m]  \\\n",
       "0                                 2.08                        1.71   \n",
       "1                                 4.47                        3.67   \n",
       "2                                 2.98                        2.44   \n",
       "3                                 2.98                        2.44   \n",
       "\n",
       "  Optical Factor,  Q [-]  \n",
       "0                   1.19  \n",
       "1                    1.0  \n",
       "2                    1.0  \n",
       "3                  0.333  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Generate OUPUT summary TABLE\n",
    "data = {\n",
    "    'Satellite': ['SSOT_SSO', '3U_Dove_SSO', '3U_Dove_ISS', '1U_Cubesat_ISS'], #Satellite names\n",
    "    'Pixel pitch, p [m]': ['{:.2e}'.format(val) for val in p], #pixel in detector physical dimension (size) \n",
    "    'Satellite Altitude, H [m]': ['{:.2e}'.format(val) for val in H], \n",
    "    'Instrumental Focal Length, f [m]': f, \n",
    "    'Ground Sample Distance, R_GSD [m]': ['{:.3}'.format(val) for val in R_GSD],\n",
    "    'Average Wavelength, $\\lambda$ [m]': ['{:.2e}'.format(val) for val in lambd], \n",
    "    'Diameter, D [m]': D,\n",
    "    'Rayleigh Difraction Limit, R_RDL [m]': ['{:.3}'.format(val) for val in R_RDL],\n",
    "    'Ground Spot Size, R_GSS [m]':['{:.3}'.format(val) for val in R_GSS],\n",
    "    'Optical Factor,  Q [-]': ['{:.3}'.format(val) for val in Q]\n",
    "}\n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09044e82",
   "metadata": {},
   "source": [
    "Note that DOVE are 3U cubesats, constrained by the CDS to $10\\times 10 \\times 30 cm^3$ which ends in a maximum freasible aperture of 9 cm leaving some space for the structure, and the focal lenght on $~3\\times$ the z-axis through the use of mirrors. While SSOT corresponds to a 140 kg small satellite deployed in 2011.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe64afa",
   "metadata": {},
   "source": [
    "## WP04.01 & WP04.03 Sizing spatial resolution for orbital estimating data rates of payload\n",
    "\n",
    "As said, previously the preovius block worked as a context for understanding the capabilities as well as upper and lower limits of the constants being used in this problem. Specifically, it was probed that a GSD can be as low as 3.67 [m] however previous iterations of this problem showed a GSD as low as that is far demanding for the link budget. \n",
    "\n",
    "In this section, several values of spatial resolution in terms of $R_GSD$ and orbit altitudes are defined in order to iterate and define the most suitable scenario to accomplish this mission. \n",
    "\n",
    "\n",
    "### Swadth width discussion\n",
    "\n",
    "Figure XX provides and overview of Planet sensors characteristics that are relevant for the sizing by analogy of our Payload.\n",
    "\n",
    "![planetscopes sensores.jpg](../Figs/planetscopes%20sensores.jpg)\n",
    "\n",
    "Planet source: https://www.mdpi.com/2072-4292/13/19/3930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf83dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_GSD= 25\n",
    "\n",
    "H= 4.5e5\n",
    "\n",
    "S_w=np.array([19000, 22000, 25000, 30000, 35000, 45000]) ## [m] Estimated from equivalent CubeSat for fire monitoring mission [Asamis et al, 2022]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b50ad7",
   "metadata": {},
   "source": [
    "## WP04.02 Link sizing and analysis\n",
    "\n",
    "## WP04.03 Payload Data Rate (DR) generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0969a5e",
   "metadata": {},
   "source": [
    "The data rate from the payload (i.e generate: _gen) from the image is estimated from: \n",
    "\n",
    "$$ DR_{gen}= \\frac{S_w V_g}{R_{GSD}}b \\;\\left[ \\frac{bit}{s} \\right] $$\n",
    "\n",
    "Where\n",
    "- $S_w$: Swadth width [m] set as 25 [km] from [Azami et al., 2022]\n",
    "- $b$ : bit rate [bit/s]. Set as 12 [bit/s] from KITSUNE forest monitoring CubeSat mission [Azami et al., 2022]\n",
    "- $R_{GSD}$: Ground Sample Distance resolution [m], estimeted previously based on the relationships by [Valenzuela & Reyes 2019].\n",
    "\n",
    "@Note to loosen, i.e. make the R_{GSD} 25 [m] for FireSat scenario. Required resolution is 50 m \n",
    "@AL: add ref to firesat II resolution req.\n",
    "\n",
    "- $V_g$: Ground speed [m/s], estimated as follows [New SMAD - Appendix C]:\n",
    "\n",
    "\n",
    "$$ V_{g}= \\sqrt{\\mu_E\\frac{1}{R_{E}+H}} \\; [\\frac{m}{s}]$$\n",
    "\n",
    "Where:\n",
    "- $\\mu_E=3.986004356e14 [m^3/s^2]$ Earth Gravitational Constant  [New SMAD - Spaceflight constants]\n",
    "- $R_{E}=6378136.6 [m]$ Earth equatorial radius [New SMAD - Spaceflight constants]\n",
    "- $H$ orbital height [m]. From the previous cases defined in the INPUT H vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f1efafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload data rate: 91.6851563957838  [Mbit/s]\n"
     ]
    }
   ],
   "source": [
    "## SSO a 600 [km],  GSD 25 [m] y S_w 25 [km]-> R_GSD[9], H[1],  S[2]\n",
    "\n",
    "\n",
    "## Payload Data Rate sizing relations \n",
    "mu= 3.986004356e14 ## [m^3/s^2] [New SMAD - Spaceflight constants]\n",
    "R_E=6378136.6 ## [m]$ Earth equatorial radius [m] [New SMAD - Spaceflight constants]\n",
    "\n",
    "V_g= np.sqrt(mu*(1/(R_E+H))) ## [m/s]\n",
    "\n",
    "b=12 # [bit]\n",
    "\n",
    "D_rategenerated= S_w[2]* V_g*b/(R_GSD) #[bit/s]\n",
    "print('Payload data rate:', D_rategenerated / 1000000, ' [Mbit/s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44675e5",
   "metadata": {},
   "source": [
    "## PROCESS: DATA GENERATION AND DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12894c8",
   "metadata": {},
   "source": [
    "In order to quantify the amount of generated data, the previously calculated data rate ($D_{rategenerated}$) and the median contact time are used such that: \n",
    "\n",
    "$$ D_{gen}= D_{rategenerated}*t_{AOI} \\; [Mbit] $$\n",
    "\n",
    "As well to quantify the amount of downloaded data, the download datarate and the median contact time to the ground station are used such that: \n",
    "$$ D_{down}= D_{ratedown} *t_{Contact time}  \\; [Mbit]$$\n",
    "\n",
    "Both times $t_{AOI}$ and $t_{contacttime}$ are calculated up next by using the inputs as the results of the simulations on FreeFlyer. The results are extracted both for the cluster in total and for each individual satellite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cca72a",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "The following section compiles the previous setup for the program, stating the main relevant variables and libraries to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f32406b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries used\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# File Paths\\n,\n",
    "# For convenience, the filepaths for each file used will be edited in this cell for user convenience.\n",
    "FilePathAreaofInterest = 'INPUTS\\Scenario1-10sats-SSO-6828km-97.21deg-30d-25mGSD\\Contact_Region_SSO_6828_97.21_30_days_R_GSD-25.00.txt'\n",
    "FilePathSvalbard = 'INPUTS\\Scenario1-10sats-SSO-6828km-97.21deg-30d-25mGSD\\Contact_Times_Svalbard_SSO_6828_97.21_30_days_R_GSD-25.00.txt'\n",
    "FilePathCuiaba = 'INPUTS\\Scenario1-10sats-SSO-6828km-97.21deg-30d-25mGSD\\Contact_Times_Cuiaba_SSO_6828_97.21_30_days_R_GSD-25.00.txt'\n",
    "FilePathPuntaArenas = 'INPUTS\\Scenario1-10sats-SSO-6828km-97.21deg-30d-25mGSD\\Contact_Times_PuntaArenas_SSO_6828_97.21_30_days_R_GSD-25.00.txt'\n",
    "\n",
    "# Simulation timespan\n",
    "# For aesthetic purposes, please add the simulation time in this variable for title purposes on the graphs\n",
    "simulation_time = 30\n",
    "F_SCamount = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274b2306",
   "metadata": {},
   "source": [
    "### Time contact Area Of Interest\n",
    "\n",
    "\n",
    "This algorithm/script takes the OUTPUT contact times from the FreeFlyer Orbital Scenario simulation and obtains per satellite over the area of interest (AoI)\n",
    "\n",
    "The FREE Flyer OUTPUT with contact times should be name \"Contact_Region.txt\" and store in the respective \"(ISS or SSO)_xxd\" where xx is the amount of days of the simulation, these folders should be located inside \"INPUTS\" folder of this repository.\n",
    "\n",
    "Note the satellite names should be the same as the ones used in the orbital simulation (i.e. Walker_XX)\n",
    "Contact time data should be between columns  114 and 125 in the txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c97a166",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'INPUTS\\\\Scenario1-10sats-SSO-6828km-97.21deg-30d-25mGSD\\\\Contact_Region_SSO_6828_97.21_30_days_R_GSD-25.00.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_date\u001b[39m(date_string):    \u001b[38;5;66;03m#Defining the date format.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m datetime\u001b[38;5;241m.\u001b[39mstrptime(date_string, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#b for abreviated month (Jan, Feb, etc), d for day (01, 02, etc, 10) and Y for year (2022, 2023, etc)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFilePathAreaofInterest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:   \u001b[38;5;66;03m#INPUT/SSO_15d contact report location.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     lines \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadlines()   \u001b[38;5;66;03m#Determines how long should the script be i.e. total lines the FreeFlyer file. \u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#Initialize vectors to store data in.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'INPUTS\\\\Scenario1-10sats-SSO-6828km-97.21deg-30d-25mGSD\\\\Contact_Region_SSO_6828_97.21_30_days_R_GSD-25.00.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "def parse_date(date_string):    #Defining the date format.\n",
    "    return datetime.strptime(date_string, '%b %d %Y') #b for abreviated month (Jan, Feb, etc), d for day (01, 02, etc, 10) and Y for year (2022, 2023, etc)\n",
    "\n",
    "with open(FilePathAreaofInterest, 'r') as file:   #INPUT/SSO_15d contact report location.\n",
    "    lines = file.readlines()   #Determines how long should the script be i.e. total lines the FreeFlyer file. \n",
    "\n",
    "#Initialize vectors to store data in.\n",
    "\n",
    "Walker_01_AOI = []    \n",
    "Walker_02_AOI = []\n",
    "Walker_03_AOI = []\n",
    "Walker_04_AOI = []\n",
    "Walker_05_AOI = []\n",
    "Walker_06_AOI = []\n",
    "Walker_07_AOI = []\n",
    "Walker_08_AOI = []\n",
    "Walker_09_AOI = []\n",
    "Walker_10_AOI = []\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    if not line.strip() or 'Entry Epoch' in line:\n",
    "        continue  \n",
    "    parts = line.split()\n",
    "    if len(parts) < 7:  \n",
    "        continue  ## Reads the \"Entry Epoch\" column of the output file and checks if the length matches the date format entered. \n",
    " \n",
    "    satellite = parts[2]  #Reads the satellite name.\n",
    "    entry_date = parse_date(' '.join(parts[3:6]))   #Reads the date.\n",
    "    \n",
    "    duration = float(parts[-1])  #Find the duration of the contact in the last column of the output file. \n",
    "    \n",
    "    #With the read satellite name check if the date already existis, if it does adds up the contact time to the date. \n",
    "    #If not, create a new line with new date and respective contact time. \n",
    "\n",
    "    #The iterates over each line encountered in \"lines = file.readlines()\" checking each satellite and date. \n",
    "    day = entry_date.date()\n",
    "    if satellite == 'Walker_1':\n",
    "        for item in Walker_01_AOI:\n",
    "            if item[0] == day:\n",
    "                item[1] += duration\n",
    "                break\n",
    "        else:\n",
    "            Walker_01_AOI.append([day, duration])\n",
    "    elif satellite == 'Walker_2':\n",
    "        for item in Walker_02_AOI:\n",
    "            if item[0] == day:\n",
    "                item[1] += duration\n",
    "                break\n",
    "        else:\n",
    "            Walker_02_AOI.append([day, duration])\n",
    "    elif satellite == 'Walker_3':\n",
    "        for item in Walker_03_AOI:\n",
    "            if item[0] == day:\n",
    "                item[1] += duration\n",
    "                break\n",
    "        else:\n",
    "            Walker_03_AOI.append([day, duration])\n",
    "    elif satellite == 'Walker_4':\n",
    "        for item in Walker_04_AOI:\n",
    "            if item[0] == day:\n",
    "                item[1] += duration\n",
    "                break\n",
    "        else:\n",
    "            Walker_04_AOI.append([day, duration])\n",
    "    elif satellite == 'Walker_5':\n",
    "        for item in Walker_05_AOI:\n",
    "            if item[0] == day:\n",
    "                item[1] += duration\n",
    "                break\n",
    "        else:\n",
    "            Walker_05_AOI.append([day, duration])\n",
    "    elif satellite == 'Walker_6':\n",
    "        for item in Walker_06_AOI:\n",
    "            if item[0] == day:\n",
    "                item[1] += duration\n",
    "                break\n",
    "        else:\n",
    "            Walker_06_AOI.append([day, duration])\n",
    "    elif satellite == 'Walker_7':\n",
    "        for item in Walker_07_AOI:\n",
    "            if item[0] == day:\n",
    "                item[1] += duration\n",
    "                break\n",
    "        else:\n",
    "            Walker_07_AOI.append([day, duration])\n",
    "    elif satellite == 'Walker_8':\n",
    "        for item in Walker_08_AOI:\n",
    "            if item[0] == day:\n",
    "                item[1] += duration\n",
    "                break\n",
    "        else:\n",
    "            Walker_08_AOI.append([day, duration])\n",
    "    elif satellite == 'Walker_9':\n",
    "        for item in Walker_09_AOI:\n",
    "            if item[0] == day:\n",
    "                item[1] += duration\n",
    "                break\n",
    "        else:\n",
    "            Walker_09_AOI.append([day, duration])\n",
    "    elif satellite == 'Walker_10':\n",
    "        for item in Walker_10_AOI:\n",
    "            if item[0] == day:\n",
    "                item[1] += duration\n",
    "                break\n",
    "        else:\n",
    "            Walker_10_AOI.append([day, duration])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434202b",
   "metadata": {},
   "source": [
    "### Time contact per Ground Station\n",
    "\n",
    "\n",
    "This algorithm/script takes the OUTPUT contact times to Ground Stations from the FreeFlyer Orbital Scenario simulation and obtains connection time for all three Ground Station per satellite per day. The script uses a condition for time named t_min which is the minimal time asked to operate, the conditions is asigned by the user and it should be unerstood as the minimal time in which a connection between Ground station and satellite can be done. \n",
    "\n",
    "The FREE Flyer OUTPUT with contact times should be name \"Contact_Times_GroundStation.txt\" where GroundStation can be PuntaArenas, Svalbard or Cuiaba and store in the respective \"(ISS or SSO)_xxd\" where xx is the amount of days of the simulation, these folders should be located inside \"INPUTS\" folder of this repository.\n",
    "\n",
    "Note the satellite names should be the same as the ones used in the orbital simulation (i.e. Walker_XX).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9beac0",
   "metadata": {},
   "source": [
    "#### Svalbard Contact time per day per satellite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53500622",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_min=5 #[min]. Connection time filter\n",
    "\n",
    "def parse_date(date_string): #Date format definition. \n",
    "    return datetime.strptime(date_string, '%b %d %Y') \n",
    "\n",
    "with open(FilePathSvalbard, 'r') as file: #Contact_Time_Svalvard location. \n",
    "    lines = file.readlines() #Determines how long should the script be i.e. total lines the FreeFlyer file. \n",
    "\n",
    "\n",
    "#Initialize vectors to store data in.\n",
    "Walker_01_Svalbard = []\n",
    "Walker_02_Svalbard = []\n",
    "Walker_03_Svalbard = []\n",
    "Walker_04_Svalbard = []\n",
    "Walker_05_Svalbard = []\n",
    "Walker_06_Svalbard = []\n",
    "Walker_07_Svalbard = []\n",
    "Walker_08_Svalbard = []\n",
    "Walker_09_Svalbard = []\n",
    "Walker_10_Svalbard = []\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    if not line.strip() or 'Entry Epoch' in line:\n",
    "        continue  \n",
    "    parts = line.split()\n",
    "    if len(parts) < 7:  \n",
    "        continue  #Reads the \"Entry Epoch\" column of the output file and checks if the length matches the date format entered. \n",
    "\n",
    "\n",
    "    satellite = parts[2]  #Reads teh satellite name. \n",
    "    entry_date = parse_date(' '.join(parts[3:6]))  #Reads the date. \n",
    "    \n",
    "    duration = float(parts[-1]) #Find the duration of the contact in the last column of the output file. \n",
    "    \n",
    "    #With the read satellite name check if the date already exists, if it does adds up the contact time to the date. \n",
    "    #If not, create a new line with new date and respective contact time. \n",
    "\n",
    "    #Iterates over each line encountered in \"lines = file.readlines()\" checking each satellite and date. \n",
    "    day = entry_date.date()\n",
    "    if satellite == 'Walker_1':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_01_Svalbard:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_01_Svalbard.append([day, duration])\n",
    "    elif satellite == 'Walker_2':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_02_Svalbard:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_02_Svalbard.append([day, duration])\n",
    "    elif satellite == 'Walker_3':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_03_Svalbard:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_03_Svalbard.append([day, duration])\n",
    "    elif satellite == 'Walker_4':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_04_Svalbard:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_04_Svalbard.append([day, duration])\n",
    "    elif satellite == 'Walker_5':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_05_Svalbard:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_05_Svalbard.append([day, duration])\n",
    "    elif satellite == 'Walker_6':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_06_Svalbard:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_06_Svalbard.append([day, duration])\n",
    "    elif satellite == 'Walker_7':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_07_Svalbard:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_07_Svalbard.append([day, duration])\n",
    "    elif satellite == 'Walker_8':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_08_Svalbard:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_08_Svalbard.append([day, duration])\n",
    "    elif satellite == 'Walker_9':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_09_Svalbard:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_09_Svalbard.append([day, duration])\n",
    "    elif satellite == 'Walker_10':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_10_Svalbard:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_10_Svalbard.append([day, duration])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0003f1",
   "metadata": {},
   "source": [
    "#### Punta Arenas contact time per day per satellite \n",
    "\n",
    "\n",
    "Both next scripts apply the same process to its respective output file using exactly the same code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635680e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(date_string):\n",
    "    return datetime.strptime(date_string, '%b %d %Y')\n",
    "\n",
    "with open(FilePathPuntaArenas, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "Walker_01_PuntaArenas = []\n",
    "Walker_02_PuntaArenas = []\n",
    "Walker_03_PuntaArenas = []\n",
    "Walker_04_PuntaArenas = []\n",
    "Walker_05_PuntaArenas = []\n",
    "Walker_06_PuntaArenas = []\n",
    "Walker_07_PuntaArenas = []\n",
    "Walker_08_PuntaArenas = []\n",
    "Walker_09_PuntaArenas = []\n",
    "Walker_10_PuntaArenas = []\n",
    "\n",
    "for line in lines:\n",
    "    if not line.strip() or 'Entry Epoch' in line:\n",
    "        continue  \n",
    "    parts = line.split()\n",
    "    if len(parts) < 7:  \n",
    "        continue  \n",
    "    satellite = parts[2]  \n",
    "    entry_date = parse_date(' '.join(parts[3:6]))  \n",
    "    \n",
    "    duration = float(parts[-1])\n",
    "    \n",
    "    day = entry_date.date()\n",
    "    if satellite == 'Walker_1':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_01_PuntaArenas:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_01_PuntaArenas.append([day, duration])\n",
    "    elif satellite == 'Walker_2':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_02_PuntaArenas:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_02_PuntaArenas.append([day, duration])\n",
    "    elif satellite == 'Walker_3':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_03_PuntaArenas:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_03_PuntaArenas.append([day, duration])\n",
    "    elif satellite == 'Walker_4':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_04_PuntaArenas:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_04_PuntaArenas.append([day, duration])\n",
    "    elif satellite == 'Walker_5':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_05_PuntaArenas:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_05_PuntaArenas.append([day, duration])\n",
    "    elif satellite == 'Walker_6':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_06_PuntaArenas:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_06_PuntaArenas.append([day, duration])\n",
    "    elif satellite == 'Walker_7':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_07_PuntaArenas:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_07_PuntaArenas.append([day, duration])\n",
    "    elif satellite == 'Walker_8':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_08_PuntaArenas:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_08_PuntaArenas.append([day, duration])\n",
    "    elif satellite == 'Walker_9':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_09_PuntaArenas:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_09_PuntaArenas.append([day, duration])\n",
    "    elif satellite == 'Walker_10':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_10_PuntaArenas:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_10_PuntaArenas.append([day, duration])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fd399f",
   "metadata": {},
   "source": [
    "#### Cuiaba contact times per day per satellite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a89cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(date_string):\n",
    "    return datetime.strptime(date_string, '%b %d %Y')\n",
    "\n",
    "with open(FilePathCuiaba, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "Walker_01_Cuiaba = []\n",
    "Walker_02_Cuiaba = []\n",
    "Walker_03_Cuiaba = []\n",
    "Walker_04_Cuiaba = []\n",
    "Walker_05_Cuiaba = []\n",
    "Walker_06_Cuiaba = []\n",
    "Walker_07_Cuiaba = []\n",
    "Walker_08_Cuiaba = []\n",
    "Walker_09_Cuiaba = []\n",
    "Walker_10_Cuiaba = []\n",
    "\n",
    "for line in lines:\n",
    "    if not line.strip() or 'Entry Epoch' in line:\n",
    "        continue  \n",
    "    parts = line.split()\n",
    "    if len(parts) < 7:  \n",
    "        continue  \n",
    "    satellite = parts[2]  \n",
    "    entry_date = parse_date(' '.join(parts[3:6]))  \n",
    "    \n",
    "    duration = float(parts[-1])\n",
    "    \n",
    "    day = entry_date.date()\n",
    "    if satellite == 'Walker_1':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_01_Cuiaba:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_01_Cuiaba.append([day, duration])\n",
    "    elif satellite == 'Walker_2':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_02_Cuiaba:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_02_Cuiaba.append([day, duration])\n",
    "    elif satellite == 'Walker_3':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_03_Cuiaba:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_03_Cuiaba.append([day, duration])\n",
    "    elif satellite == 'Walker_4':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_04_Cuiaba:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_04_Cuiaba.append([day, duration])\n",
    "    elif satellite == 'Walker_5':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_05_Cuiaba:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_05_Cuiaba.append([day, duration])\n",
    "    elif satellite == 'Walker_6':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_06_Cuiaba:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_06_Cuiaba.append([day, duration])\n",
    "    elif satellite == 'Walker_7':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_07_Cuiaba:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_07_Cuiaba.append([day, duration])\n",
    "    elif satellite == 'Walker_8':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_08_Cuiaba:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_08_Cuiaba.append([day, duration])\n",
    "    elif satellite == 'Walker_9':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_09_Cuiaba:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_09_Cuiaba.append([day, duration])\n",
    "    elif satellite == 'Walker_10':\n",
    "        if duration >= t_min:\n",
    "            for item in Walker_10_Cuiaba:\n",
    "                if item[0] == day:\n",
    "                    item[1] += duration\n",
    "                    break\n",
    "            else:\n",
    "                Walker_10_Cuiaba.append([day, duration])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f2b450",
   "metadata": {},
   "source": [
    "### OUTPUT: Can we download the data?\n",
    "- Desired outputs are total generated data per satellite\n",
    "- Downloadable data per ground station alone (per satellite)\n",
    "- Combination of 2 or 3 GS per satellite\n",
    "\n",
    "Calculations of Download data rate $D_{downrate}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d5594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "D_ratedown=6 #[Mbps] Design parameter based on Band S capabilities (estimated by analogy or Datasheet for S-band transponder)\n",
    "             #Look for the ref\n",
    "\n",
    "\n",
    "\n",
    "#In case some of the outputs doesnt have results for each day, this function will creae and fill out the non existing dates with 0 [min] contact time.\n",
    "def fill_missing_data(array, all_dates):\n",
    "    filled_values = []\n",
    "    for date in all_dates:\n",
    "        match = np.where(array[:, 0] == date)[0]\n",
    "        if match.size == 0:\n",
    "            filled_values.append([date, 0])  \n",
    "        else:\n",
    "            filled_values.append(array[match[0]])  \n",
    "    return np.array(filled_values)\n",
    "\n",
    "\n",
    "\n",
    "#The following function graphs a bar plot of data generated and downloaded for one satellite and the prefered Ground Station.\n",
    "# Each required variable and the output its explained below: \n",
    "# Vector_AOI: Vector of contact time of the desired satellite over area of interes. \n",
    "# Vector_GS1: Vector of contact time between Ground Station 1 and desired satellite.\n",
    "# Vector_GS2: Vector of contact time between Ground Station 2 and desired satellite.\n",
    "# Vector_GS3: Vector of contact time between Ground Station 3 and desired satellite.\n",
    "# D_rategenerated: Value of data rate generation calculated above. IN [BIT/S]\n",
    "# D_ratedown: Value of data rate download defined above\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def graficar(vector_AOI, vector_GS1,vector_GS2,vector_GS3,D_rategenerated,D_ratedown,auxiliar,sat,GS1,GS2,GS3):\n",
    "\n",
    "    if auxiliar==1:\n",
    "        vector_AOI=np.array(vector_AOI)\n",
    "        vector_GS1=np.array(vector_GS1)\n",
    "        D_gen=[[row[0],row[1]*D_rategenerated*60/1e6] for row in vector_AOI]\n",
    "        D_down=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_GS1]\n",
    "       \n",
    "\n",
    "        values_filled_D_gen_01 = fill_missing_data(np.array(D_gen), vector_GS1[:,0])\n",
    "        values_filled_D_down_01 = fill_missing_data(np.array(D_down), vector_GS1[:,0])\n",
    "        \n",
    "        species = (vector_GS1[:,0])\n",
    "        penguin_means = {\n",
    "          'Data generated': values_filled_D_gen_01[:,1] ,\n",
    "          'Data ' + str(GS1): values_filled_D_down_01[:,1],\n",
    "          }\n",
    "        x = np.arange(len(species))  \n",
    "        width = 0.25  \n",
    "        multiplier = 0\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        for attribute, measurement in penguin_means.items():\n",
    "            offset = width * multiplier\n",
    "            rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "            multiplier += 1\n",
    "\n",
    "        ax.set_ylabel('Data [Mbit]')\n",
    "        ax.set_xticks(x + width / 2, species)  \n",
    "        ax.set_xticklabels(species, fontsize='small', rotation=45, ha='right')\n",
    "        ax.legend(loc='best')\n",
    "        ax.grid(True)\n",
    "        ax.set_ylim(0, 75000)\n",
    "        plt.show()  \n",
    "\n",
    "\n",
    "    if auxiliar==2:\n",
    "        vector_AOI=np.array(vector_AOI)\n",
    "        vector_GS1=np.array(vector_GS1)\n",
    "        vector_GS2=np.array(vector_GS2)\n",
    "\n",
    "        D_gen=[[row[0],row[1]*D_rategenerated*60/1e6] for row in vector_AOI]\n",
    "        D_down1=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_GS1]\n",
    "        D_down2=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_GS2]\n",
    "       \n",
    "\n",
    "        values_filled_D_gen_01 = fill_missing_data(np.array(D_gen), vector_GS1[:,0])\n",
    "        values_filled_D_down_01 = fill_missing_data(np.array(D_down1), vector_GS1[:,0])\n",
    "        values_filled_D_down_02= fill_missing_data(np.array(D_down2), vector_GS2[:,0])\n",
    "\n",
    "        bottom = np.zeros(simulation_time)\n",
    "\n",
    "        species = (vector_GS1[:,0])\n",
    "        penguin_means = {\n",
    "          'Data generated': tuple(values_filled_D_gen_01[:,1]),\n",
    "          'Data ' + str(GS1): tuple(values_filled_D_down_01[:,1]),\n",
    "          'Data ' + str(GS2): tuple(values_filled_D_down_02[:,1]),\n",
    "          }\n",
    "        x = np.arange(len(species))\n",
    "        width = 0.25  \n",
    "        multiplier = 0\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        for attribute, measurement in penguin_means.items():\n",
    "            offset = width * multiplier\n",
    "            if attribute == 'Data generated':\n",
    "                rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "                multiplier += 1\n",
    "            else:\n",
    "                rects = ax.bar(x + offset, measurement, width, label=attribute, bottom=bottom)\n",
    "                bottom += measurement\n",
    "\n",
    "        ax.set_ylabel('Data [Mbit]')\n",
    "        ax.set_xticks(x + width / 2, species) \n",
    "        ax.set_xticklabels(species, fontsize='small', rotation=45, ha='right')\n",
    "        ax.legend(loc='best')\n",
    "        ax.grid(True)\n",
    "        ax.set_ylim(0, 75000)\n",
    "        plt.show() \n",
    "\n",
    "    if auxiliar==3:\n",
    "        vector_AOI=np.array(vector_AOI)\n",
    "        vector_GS1=np.array(vector_GS1)\n",
    "        vector_GS2=np.array(vector_GS2)\n",
    "        vector_GS3=np.array(vector_GS3)\n",
    "\n",
    "        D_gen=[[row[0],row[1]*D_rategenerated*60/1e6] for row in vector_AOI]\n",
    "        D_down1=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_GS1]\n",
    "        D_down2=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_GS2]\n",
    "        D_down3=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_GS3]\n",
    "       \n",
    "        values_filled_D_gen_01 = fill_missing_data(np.array(D_gen), vector_GS1[:,0])\n",
    "\n",
    "        values_filled_D_down_01= fill_missing_data(np.array(D_down1), vector_GS1[:,0])\n",
    "        values_filled_D_down_02= fill_missing_data(np.array(D_down2), vector_GS2[:,0])\n",
    "        values_filled_D_down_03= fill_missing_data(np.array(D_down3), vector_GS3[:,0])\n",
    "\n",
    "        species = (vector_GS1[:,0])\n",
    "        penguin_means = {\n",
    "          'Data generated': tuple(values_filled_D_gen_01[:,1]),\n",
    "          'Data ' + str(GS1): tuple(values_filled_D_down_01[:,1]),\n",
    "          'Data ' + str(GS2): tuple(values_filled_D_down_02[:,1]),\n",
    "          'Data ' + str(GS3): tuple(values_filled_D_down_03[:,1]),\n",
    "          }\n",
    "        x = np.arange(len(species))\n",
    "        width = 0.25  \n",
    "        multiplier = 0\n",
    "        bottom = np.zeros(simulation_time)\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        for attribute, measurement in penguin_means.items():\n",
    "            offset = width * multiplier\n",
    "            if attribute == 'Data generated':\n",
    "                rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "                multiplier += 1\n",
    "            else:\n",
    "                rects = ax.bar(x + offset, measurement, width, label=attribute, bottom=bottom)\n",
    "                bottom += measurement\n",
    "\n",
    "        ax.set_ylabel('Data [Mbit]')\n",
    "        ax.set_xticks(x + width / 2, species)  \n",
    "        ax.set_xticklabels(species, fontsize='small', rotation=45, ha='right')  \n",
    "        ax.legend(loc='best')\n",
    "        ax.grid(True)\n",
    "        ax.set_ylim(0, 75000)\n",
    "        plt.show()  \n",
    "    \n",
    "    return \n",
    "\n",
    "graf1=graficar(Walker_01_AOI,Walker_01_PuntaArenas,Walker_01_Svalbard,Walker_01_Cuiaba,D_rategenerated,D_ratedown,1,'Walker 01','Punta Arenas','Svalbard','Cuiaba')\n",
    "graf2=graficar(Walker_01_AOI,Walker_01_PuntaArenas,Walker_01_Svalbard,Walker_01_Cuiaba,D_rategenerated,D_ratedown,2,'Walker 01','Punta Arenas','Svalbard','Cuiaba')\n",
    "graf3=graficar(Walker_01_AOI,Walker_01_PuntaArenas,Walker_01_Svalbard,Walker_01_Cuiaba,D_rategenerated,D_ratedown,3,'Walker 01','Punta Arenas','Svalbard','Cuiaba')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de7f01c",
   "metadata": {},
   "source": [
    "### Contact times to Ground stations per satellite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b209eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiempos_GS(vector_GS1,vector_GS2,vector_GS3,sat,GS1,GS2,GS3): \n",
    "\n",
    "  vector_GS1=np.array(vector_GS1)\n",
    "  vector_GS2=np.array(vector_GS2)\n",
    "  vector_GS3=np.array(vector_GS3)\n",
    "    \n",
    "  ejex = (vector_GS1[:,0])\n",
    "  barras = {\n",
    "  'Time to '+str(GS1)+'': vector_GS1[:,1],\n",
    "  'Time to '+str(GS2)+'': vector_GS2[:,1],\n",
    "  'Time to '+str(GS3)+'': vector_GS3[:,1],\n",
    "  }\n",
    "\n",
    "  x = np.arange(len(ejex))\n",
    "  width = 0.25  \n",
    "  multiplier = 0\n",
    "  fig, ax = plt.subplots()\n",
    "\n",
    "  for attribute, measurement in barras.items():\n",
    "   offset = width * multiplier\n",
    "   rects = ax.bar(x + offset, measurement, width, label=attribute) \n",
    "   multiplier += 1\n",
    "\n",
    "\n",
    "  ax.set_ylabel('Time [min]')\n",
    "  ax.set_xticks(x + width * 1) \n",
    "  ax.set_xticklabels(ejex, fontsize='small', rotation=45, ha='right')\n",
    "  ax.legend(loc='best')\n",
    "  ax.grid(True, linewidth=0.5, linestyle=':', alpha=0.5)  # Adjust grid thickness, style, and transparency\n",
    "  plt.show()\n",
    "       \n",
    "  return \n",
    "\n",
    "tiempos_GS(Walker_01_PuntaArenas, Walker_01_Svalbard, Walker_01_Cuiaba,'Walker 01','Punta Arenas','Svalbard','Cuiaba')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d5593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of times of contact between all sats\n",
    "\n",
    "def graficarsuma(Walker_01_AOI,Walker_02_AOI,Walker_03_AOI,Walker_04_AOI,Walker_05_AOI,Walker_06_AOI,Walker_07_AOI,Walker_08_AOI,Walker_09_AOI,Walker_10_AOI,\n",
    "                  Walker_01_Svalbard,Walker_02_Svalbard,Walker_03_Svalbard,Walker_04_Svalbard,Walker_05_Svalbard,Walker_06_Svalbard,Walker_07_Svalbard,Walker_08_Svalbard,Walker_09_Svalbard,Walker_10_Svalbard,\n",
    "                  Walker_01_PuntaArenas,Walker_02_PuntaArenas,Walker_03_PuntaArenas,Walker_04_PuntaArenas,Walker_05_PuntaArenas,Walker_06_PuntaArenas,Walker_07_PuntaArenas,Walker_08_PuntaArenas,Walker_09_PuntaArenas,Walker_10_PuntaArenas,\n",
    "                  Walker_01_Cuiaba,Walker_02_Cuiaba,Walker_03_Cuiaba,Walker_04_Cuiaba,Walker_05_Cuiaba,Walker_06_Cuiaba,Walker_07_Cuiaba,Walker_08_Cuiaba,Walker_09_Cuiaba,Walker_10_Cuiaba,\n",
    "                  D_rategenerated,D_ratedown,GS1,GS2,GS3):\n",
    "\n",
    "    vector_Walker_1_AOI=np.array(Walker_01_AOI)\n",
    "    vector_Walker_2_AOI=np.array(Walker_02_AOI)\n",
    "    vector_Walker_3_AOI=np.array(Walker_03_AOI)\n",
    "    vector_Walker_4_AOI=np.array(Walker_04_AOI)\n",
    "    vector_Walker_5_AOI=np.array(Walker_05_AOI)\n",
    "    vector_Walker_6_AOI=np.array(Walker_06_AOI)\n",
    "    vector_Walker_7_AOI=np.array(Walker_07_AOI)\n",
    "    vector_Walker_8_AOI=np.array(Walker_08_AOI)\n",
    "    vector_Walker_9_AOI=np.array(Walker_09_AOI)\n",
    "    vector_Walker_10_AOI=np.array(Walker_10_AOI)\n",
    "\n",
    "    vector_Walker_1_GS1=np.array(Walker_01_Svalbard)\n",
    "    vector_Walker_2_GS1=np.array(Walker_02_Svalbard)\n",
    "    vector_Walker_3_GS1=np.array(Walker_03_Svalbard)\n",
    "    vector_Walker_4_GS1=np.array(Walker_04_Svalbard)\n",
    "    vector_Walker_5_GS1=np.array(Walker_05_Svalbard)\n",
    "    vector_Walker_6_GS1=np.array(Walker_06_Svalbard)\n",
    "    vector_Walker_7_GS1=np.array(Walker_07_Svalbard)\n",
    "    vector_Walker_8_GS1=np.array(Walker_08_Svalbard)\n",
    "    vector_Walker_9_GS1=np.array(Walker_09_Svalbard)\n",
    "    vector_Walker_10_GS1=np.array(Walker_10_Svalbard)\n",
    "\n",
    "    vector_Walker_1_GS2=np.array(Walker_01_PuntaArenas)\n",
    "    vector_Walker_2_GS2=np.array(Walker_02_PuntaArenas)\n",
    "    vector_Walker_3_GS2=np.array(Walker_03_PuntaArenas)\n",
    "    vector_Walker_4_GS2=np.array(Walker_04_PuntaArenas)\n",
    "    vector_Walker_5_GS2=np.array(Walker_05_PuntaArenas)\n",
    "    vector_Walker_6_GS2=np.array(Walker_06_PuntaArenas)\n",
    "    vector_Walker_7_GS2=np.array(Walker_07_PuntaArenas)\n",
    "    vector_Walker_8_GS2=np.array(Walker_08_PuntaArenas)\n",
    "    vector_Walker_9_GS2=np.array(Walker_09_PuntaArenas)\n",
    "    vector_Walker_10_GS2=np.array(Walker_10_PuntaArenas)\n",
    "\n",
    "    vector_Walker_1_GS3=np.array(Walker_01_Cuiaba)\n",
    "    vector_Walker_2_GS3=np.array(Walker_02_Cuiaba)\n",
    "    vector_Walker_3_GS3=np.array(Walker_03_Cuiaba)\n",
    "    vector_Walker_4_GS3=np.array(Walker_04_Cuiaba)\n",
    "    vector_Walker_5_GS3=np.array(Walker_05_Cuiaba)\n",
    "    vector_Walker_6_GS3=np.array(Walker_06_Cuiaba)\n",
    "    vector_Walker_7_GS3=np.array(Walker_07_Cuiaba)\n",
    "    vector_Walker_8_GS3=np.array(Walker_08_Cuiaba)\n",
    "    vector_Walker_9_GS3=np.array(Walker_09_Cuiaba)\n",
    "    vector_Walker_10_GS3=np.array(Walker_10_Cuiaba)\n",
    "\n",
    "\n",
    "    D_gen_1=[[row[0],row[1]*D_rategenerated*60/1e6] for row in vector_Walker_1_AOI]\n",
    "    D_gen_2=[[row[0],row[1]*D_rategenerated*60/1e6] for row in vector_Walker_2_AOI]\n",
    "    D_gen_3=[[row[0],row[1]*D_rategenerated*60/1e6] for row in vector_Walker_3_AOI]\n",
    "    D_gen_4=[[row[0],row[1]*D_rategenerated*60/1e6] for row in vector_Walker_4_AOI]\n",
    "    D_gen_5=[[row[0],row[1]*D_rategenerated*60/1e6] for row in vector_Walker_5_AOI]\n",
    "    D_gen_6=[[row[0],row[1]*D_rategenerated*60/1e6] for row in vector_Walker_6_AOI]\n",
    "    D_gen_7=[[row[0],row[1]*D_rategenerated*60/1e6] for row in vector_Walker_7_AOI]\n",
    "    D_gen_8=[[row[0],row[1]*D_rategenerated*60/1e6] for row in vector_Walker_8_AOI]\n",
    "    D_gen_9=[[row[0],row[1]*D_rategenerated*60/1e6] for row in vector_Walker_9_AOI]\n",
    "    D_gen_10=[[row[0],row[1]*D_rategenerated*60/1e6] for row in vector_Walker_10_AOI]\n",
    "\n",
    "    D_down_Svalbard_1=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_1_GS1]\n",
    "    D_down_Svalbard_2=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_2_GS1]\n",
    "    D_down_Svalbard_3=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_3_GS1]\n",
    "    D_down_Svalbard_4=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_4_GS1]\n",
    "    D_down_Svalbard_5=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_5_GS1]\n",
    "    D_down_Svalbard_6=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_6_GS1]\n",
    "    D_down_Svalbard_7=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_7_GS1]\n",
    "    D_down_Svalbard_8=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_8_GS1]\n",
    "    D_down_Svalbard_9=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_9_GS1]\n",
    "    D_down_Svalbard_10=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_10_GS1]\n",
    "\n",
    "    D_down_PuntaArenas_1=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_1_GS2]\n",
    "    D_down_PuntaArenas_2=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_2_GS2]\n",
    "    D_down_PuntaArenas_3=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_3_GS2]\n",
    "    D_down_PuntaArenas_4=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_4_GS2]\n",
    "    D_down_PuntaArenas_5=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_5_GS2]\n",
    "    D_down_PuntaArenas_6=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_6_GS2]\n",
    "    D_down_PuntaArenas_7=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_7_GS2]\n",
    "    D_down_PuntaArenas_8=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_8_GS2]\n",
    "    D_down_PuntaArenas_9=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_9_GS2]\n",
    "    D_down_PuntaArenas_10=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_10_GS2]\n",
    "\n",
    "    D_down_Cuiaba_1=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_1_GS3]\n",
    "    D_down_Cuiaba_2=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_2_GS3]\n",
    "    D_down_Cuiaba_3=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_3_GS3]\n",
    "    D_down_Cuiaba_4=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_4_GS3]\n",
    "    D_down_Cuiaba_5=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_5_GS3]\n",
    "    D_down_Cuiaba_6=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_6_GS3]\n",
    "    D_down_Cuiaba_7=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_7_GS3]\n",
    "    D_down_Cuiaba_8=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_8_GS3]\n",
    "    D_down_Cuiaba_9=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_9_GS3]\n",
    "    D_down_Cuiaba_10=[[row[0],row[1]*D_ratedown*0.8*60] for row in vector_Walker_10_GS3]\n",
    "\n",
    "    values_filled_D_gen_01 = fill_missing_data(np.array(D_gen_1), vector_Walker_1_GS1[:,0])\n",
    "    values_filled_D_gen_02 = fill_missing_data(np.array(D_gen_2), vector_Walker_2_GS1[:,0])\n",
    "    values_filled_D_gen_03 = fill_missing_data(np.array(D_gen_3), vector_Walker_3_GS1[:,0])\n",
    "    values_filled_D_gen_04 = fill_missing_data(np.array(D_gen_4), vector_Walker_4_GS1[:,0])\n",
    "    values_filled_D_gen_05 = fill_missing_data(np.array(D_gen_5), vector_Walker_5_GS1[:,0])\n",
    "    values_filled_D_gen_06 = fill_missing_data(np.array(D_gen_6), vector_Walker_6_GS1[:,0])\n",
    "    values_filled_D_gen_07 = fill_missing_data(np.array(D_gen_7), vector_Walker_7_GS1[:,0])\n",
    "    values_filled_D_gen_08 = fill_missing_data(np.array(D_gen_8), vector_Walker_8_GS1[:,0])\n",
    "    values_filled_D_gen_09 = fill_missing_data(np.array(D_gen_9), vector_Walker_9_GS1[:,0])\n",
    "    values_filled_D_gen_10 = fill_missing_data(np.array(D_gen_10), vector_Walker_10_GS1[:,0])\n",
    "   \n",
    "    values_filled_D_down_Svalbard_01= fill_missing_data(np.array(D_down_Svalbard_1), vector_Walker_1_GS1[:,0])\n",
    "    values_filled_D_down_Svalbard_02= fill_missing_data(np.array(D_down_Svalbard_2), vector_Walker_2_GS1[:,0])\n",
    "    values_filled_D_down_Svalbard_03= fill_missing_data(np.array(D_down_Svalbard_3), vector_Walker_3_GS1[:,0])\n",
    "    values_filled_D_down_Svalbard_04= fill_missing_data(np.array(D_down_Svalbard_4), vector_Walker_4_GS1[:,0])\n",
    "    values_filled_D_down_Svalbard_05= fill_missing_data(np.array(D_down_Svalbard_5), vector_Walker_5_GS1[:,0])\n",
    "    values_filled_D_down_Svalbard_06= fill_missing_data(np.array(D_down_Svalbard_6), vector_Walker_6_GS1[:,0])\n",
    "    values_filled_D_down_Svalbard_07= fill_missing_data(np.array(D_down_Svalbard_7), vector_Walker_7_GS1[:,0])\n",
    "    values_filled_D_down_Svalbard_08= fill_missing_data(np.array(D_down_Svalbard_8), vector_Walker_8_GS1[:,0])\n",
    "    values_filled_D_down_Svalbard_09= fill_missing_data(np.array(D_down_Svalbard_9), vector_Walker_9_GS1[:,0])\n",
    "    values_filled_D_down_Svalbard_10= fill_missing_data(np.array(D_down_Svalbard_10), vector_Walker_10_GS1[:,0])\n",
    "\n",
    "    values_filled_D_down_PuntaArenas_01= fill_missing_data(np.array(D_down_PuntaArenas_1), vector_Walker_1_GS2[:,0])\n",
    "    values_filled_D_down_PuntaArenas_02= fill_missing_data(np.array(D_down_PuntaArenas_2), vector_Walker_2_GS2[:,0])\n",
    "    values_filled_D_down_PuntaArenas_03= fill_missing_data(np.array(D_down_PuntaArenas_3), vector_Walker_3_GS2[:,0])\n",
    "    values_filled_D_down_PuntaArenas_04= fill_missing_data(np.array(D_down_PuntaArenas_4), vector_Walker_4_GS2[:,0])\n",
    "    values_filled_D_down_PuntaArenas_05= fill_missing_data(np.array(D_down_PuntaArenas_5), vector_Walker_5_GS2[:,0])\n",
    "    values_filled_D_down_PuntaArenas_06= fill_missing_data(np.array(D_down_PuntaArenas_6), vector_Walker_6_GS2[:,0])\n",
    "    values_filled_D_down_PuntaArenas_07= fill_missing_data(np.array(D_down_PuntaArenas_7), vector_Walker_7_GS2[:,0])\n",
    "    values_filled_D_down_PuntaArenas_08= fill_missing_data(np.array(D_down_PuntaArenas_8), vector_Walker_8_GS2[:,0])\n",
    "    values_filled_D_down_PuntaArenas_09= fill_missing_data(np.array(D_down_PuntaArenas_9), vector_Walker_9_GS2[:,0])\n",
    "    values_filled_D_down_PuntaArenas_10= fill_missing_data(np.array(D_down_PuntaArenas_10), vector_Walker_10_GS2[:,0])\n",
    "\n",
    "    values_filled_D_down_Cuiaba_01= fill_missing_data(np.array(D_down_Cuiaba_1), vector_Walker_1_GS3[:,0])\n",
    "    values_filled_D_down_Cuiaba_02= fill_missing_data(np.array(D_down_Cuiaba_2), vector_Walker_2_GS3[:,0])\n",
    "    values_filled_D_down_Cuiaba_03= fill_missing_data(np.array(D_down_Cuiaba_3), vector_Walker_3_GS3[:,0])\n",
    "    values_filled_D_down_Cuiaba_04= fill_missing_data(np.array(D_down_Cuiaba_4), vector_Walker_4_GS3[:,0])\n",
    "    values_filled_D_down_Cuiaba_05= fill_missing_data(np.array(D_down_Cuiaba_5), vector_Walker_5_GS3[:,0])\n",
    "    values_filled_D_down_Cuiaba_06= fill_missing_data(np.array(D_down_Cuiaba_6), vector_Walker_6_GS3[:,0])\n",
    "    values_filled_D_down_Cuiaba_07= fill_missing_data(np.array(D_down_Cuiaba_7), vector_Walker_7_GS3[:,0])\n",
    "    values_filled_D_down_Cuiaba_08= fill_missing_data(np.array(D_down_Cuiaba_8), vector_Walker_8_GS3[:,0])\n",
    "    values_filled_D_down_Cuiaba_09= fill_missing_data(np.array(D_down_Cuiaba_9), vector_Walker_9_GS3[:,0])\n",
    "    values_filled_D_down_Cuiaba_10= fill_missing_data(np.array(D_down_Cuiaba_10), vector_Walker_10_GS3[:,0])\n",
    "\n",
    "    values_filled_Svalbard_01= fill_missing_data(vector_Walker_1_GS1, vector_Walker_1_GS1[:,0])\n",
    "    values_filled_Svalbard_02= fill_missing_data(vector_Walker_2_GS1, vector_Walker_2_GS1[:,0])\n",
    "    values_filled_Svalbard_03= fill_missing_data(vector_Walker_3_GS1, vector_Walker_3_GS1[:,0])\n",
    "    values_filled_Svalbard_04= fill_missing_data(vector_Walker_4_GS1, vector_Walker_4_GS1[:,0])\n",
    "    values_filled_Svalbard_05= fill_missing_data(vector_Walker_5_GS1, vector_Walker_5_GS1[:,0])\n",
    "    values_filled_Svalbard_06= fill_missing_data(vector_Walker_6_GS1, vector_Walker_6_GS1[:,0])\n",
    "    values_filled_Svalbard_07= fill_missing_data(vector_Walker_7_GS1, vector_Walker_7_GS1[:,0])\n",
    "    values_filled_Svalbard_08= fill_missing_data(vector_Walker_8_GS1, vector_Walker_8_GS1[:,0])\n",
    "    values_filled_Svalbard_09= fill_missing_data(vector_Walker_9_GS1, vector_Walker_9_GS1[:,0])\n",
    "    values_filled_Svalbard_10= fill_missing_data(vector_Walker_10_GS1, vector_Walker_10_GS1[:,0])\n",
    "\n",
    "    values_filled_PuntaArenas_01= fill_missing_data(vector_Walker_1_GS2, vector_Walker_1_GS2[:,0])\n",
    "    values_filled_PuntaArenas_02= fill_missing_data(vector_Walker_2_GS2, vector_Walker_2_GS2[:,0])\n",
    "    values_filled_PuntaArenas_03= fill_missing_data(vector_Walker_3_GS2, vector_Walker_3_GS2[:,0])\n",
    "    values_filled_PuntaArenas_04= fill_missing_data(vector_Walker_4_GS2, vector_Walker_4_GS2[:,0])\n",
    "    values_filled_PuntaArenas_05= fill_missing_data(vector_Walker_5_GS2, vector_Walker_5_GS2[:,0])\n",
    "    values_filled_PuntaArenas_06= fill_missing_data(vector_Walker_6_GS2, vector_Walker_6_GS2[:,0])\n",
    "    values_filled_PuntaArenas_07= fill_missing_data(vector_Walker_7_GS2, vector_Walker_7_GS2[:,0])\n",
    "    values_filled_PuntaArenas_08= fill_missing_data(vector_Walker_8_GS2, vector_Walker_8_GS2[:,0])\n",
    "    values_filled_PuntaArenas_09= fill_missing_data(vector_Walker_9_GS2, vector_Walker_9_GS2[:,0])\n",
    "    values_filled_PuntaArenas_10= fill_missing_data(vector_Walker_10_GS2, vector_Walker_10_GS2[:,0])\n",
    "\n",
    "    values_filled_Cuiaba_01= fill_missing_data(vector_Walker_1_GS3, vector_Walker_1_GS3[:,0])\n",
    "    values_filled_Cuiaba_02= fill_missing_data(vector_Walker_2_GS3, vector_Walker_2_GS3[:,0])\n",
    "    values_filled_Cuiaba_03= fill_missing_data(vector_Walker_3_GS3, vector_Walker_3_GS3[:,0])\n",
    "    values_filled_Cuiaba_04= fill_missing_data(vector_Walker_4_GS3, vector_Walker_4_GS3[:,0])\n",
    "    values_filled_Cuiaba_05= fill_missing_data(vector_Walker_5_GS3, vector_Walker_5_GS3[:,0])\n",
    "    values_filled_Cuiaba_06= fill_missing_data(vector_Walker_6_GS3, vector_Walker_6_GS3[:,0])\n",
    "    values_filled_Cuiaba_07= fill_missing_data(vector_Walker_7_GS3, vector_Walker_7_GS3[:,0])\n",
    "    values_filled_Cuiaba_08= fill_missing_data(vector_Walker_8_GS3, vector_Walker_8_GS3[:,0])\n",
    "    values_filled_Cuiaba_09= fill_missing_data(vector_Walker_9_GS3, vector_Walker_9_GS3[:,0])\n",
    "    values_filled_Cuiaba_10= fill_missing_data(vector_Walker_10_GS3, vector_Walker_10_GS3[:,0])\n",
    "\n",
    "    sum_AoI = values_filled_D_gen_01[:,1] + values_filled_D_gen_02[:,1] + values_filled_D_gen_03[:,1] + values_filled_D_gen_04[:,1] + values_filled_D_gen_05[:,1] + values_filled_D_gen_06[:,1] + values_filled_D_gen_07[:,1] + values_filled_D_gen_08[:,1] + values_filled_D_gen_09[:,1] + values_filled_D_gen_10[:,1]\n",
    "    Final_AoI=np.column_stack((values_filled_D_gen_01[:, 0], sum_AoI))\n",
    "\n",
    "    sum_Svalbard = values_filled_D_down_Svalbard_01[:,1] + values_filled_D_down_Svalbard_02[:,1] + values_filled_D_down_Svalbard_03[:,1] + values_filled_D_down_Svalbard_04[:,1] + values_filled_D_down_Svalbard_05[:,1] + values_filled_D_down_Svalbard_06[:,1] + values_filled_D_down_Svalbard_07[:,1] + values_filled_D_down_Svalbard_08[:,1] + values_filled_D_down_Svalbard_09[:,1] + values_filled_D_down_Svalbard_10[:,1]\n",
    "    Final_Svalbard=np.column_stack((values_filled_D_down_Svalbard_01[:, 0], sum_Svalbard))\n",
    "\n",
    "    Sum_times_Svalbard = values_filled_Svalbard_01[:,1] + values_filled_Svalbard_02[:,1] + values_filled_Svalbard_03[:,1] + values_filled_Svalbard_04[:,1] + values_filled_Svalbard_05[:,1] + values_filled_Svalbard_06[:,1] + values_filled_Svalbard_07[:,1] + values_filled_Svalbard_08[:,1] + values_filled_Svalbard_09[:,1] + values_filled_Svalbard_10[:,1] \n",
    "    Final_Times_Svalbard=np.column_stack((values_filled_Svalbard_01[:, 0], Sum_times_Svalbard))\n",
    "    \n",
    "    sum_PuntaArenas = values_filled_D_down_PuntaArenas_01[:,1] + values_filled_D_down_PuntaArenas_02[:,1] + values_filled_D_down_PuntaArenas_03[:,1] + values_filled_D_down_PuntaArenas_04[:,1] + values_filled_D_down_PuntaArenas_05[:,1] + values_filled_D_down_PuntaArenas_06[:,1] + values_filled_D_down_PuntaArenas_07[:,1] + values_filled_D_down_PuntaArenas_08[:,1] + values_filled_D_down_PuntaArenas_09[:,1] + values_filled_D_down_PuntaArenas_10[:,1]\n",
    "    Final_PuntaArenas=np.column_stack((values_filled_D_down_PuntaArenas_01[:, 0], sum_PuntaArenas))\n",
    "\n",
    "    Sum_times_PuntaArenas = values_filled_PuntaArenas_01[:,1] + values_filled_PuntaArenas_02[:,1] + values_filled_PuntaArenas_03[:,1] + values_filled_PuntaArenas_04[:,1] + values_filled_PuntaArenas_05[:,1] + values_filled_PuntaArenas_06[:,1] + values_filled_PuntaArenas_07[:,1] + values_filled_PuntaArenas_08[:,1] + values_filled_PuntaArenas_09[:,1] + values_filled_PuntaArenas_10[:,1]\n",
    "    Final_Times_PuntaArenas=np.column_stack((values_filled_PuntaArenas_01[:, 0], Sum_times_PuntaArenas))\n",
    "\n",
    "    sum_Cuiaba = values_filled_D_down_Cuiaba_01[:,1] + values_filled_D_down_Cuiaba_02[:,1] + values_filled_D_down_Cuiaba_03[:,1] + values_filled_D_down_Cuiaba_04[:,1] + values_filled_D_down_Cuiaba_05[:,1] + values_filled_D_down_Cuiaba_06[:,1] + values_filled_D_down_Cuiaba_07[:,1] + values_filled_D_down_Cuiaba_08[:,1] + values_filled_D_down_Cuiaba_09[:,1] + values_filled_D_down_Cuiaba_10[:,1]\n",
    "    Final_Cuiaba=np.column_stack((values_filled_D_down_Cuiaba_01[:, 0], sum_Cuiaba))\n",
    "\n",
    "    Sum_times_Cuiaba = values_filled_Cuiaba_01[:,1] + values_filled_Cuiaba_02[:,1] + values_filled_Cuiaba_03[:,1] + values_filled_Cuiaba_04[:,1] + values_filled_Cuiaba_05[:,1] + values_filled_Cuiaba_06[:,1] + values_filled_Cuiaba_07[:,1] + values_filled_Cuiaba_08[:,1] + values_filled_Cuiaba_09[:,1] + values_filled_Cuiaba_10[:,1]\n",
    "    Final_Times_Cuiaba=np.column_stack((values_filled_D_down_Cuiaba_01[:, 0], Sum_times_Cuiaba))\n",
    "\n",
    "    times = {\n",
    "        'Time to '+str(GS1)+'': tuple(Final_Times_Svalbard[:,1]),\n",
    "        'Time to '+str(GS2)+'': tuple(Final_Times_PuntaArenas[:,1]),\n",
    "        'Time to '+str(GS3)+'': tuple(Final_Times_Cuiaba[:,1]),\n",
    "    }\n",
    "\n",
    "    species = (vector_Walker_1_GS1[:,0])\n",
    "    penguin_means = {\n",
    "        'Data generated': tuple(Final_AoI[:,1]),\n",
    "        'Data ' + str(GS1): tuple(Final_Svalbard[:,1]),\n",
    "        'Data ' + str(GS2): tuple(Final_PuntaArenas[:,1]),\n",
    "        'Data ' + str(GS3): tuple(Final_Cuiaba[:,1]),\n",
    "    }\n",
    "    \n",
    "\n",
    "\n",
    "    x = np.arange(len(species))\n",
    "    width = 0.25  \n",
    "    multiplier = 0\n",
    "    bottom = np.zeros(simulation_time)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for attribute, measurement in penguin_means.items():\n",
    "        offset = width * multiplier\n",
    "        if attribute == 'Data generated':\n",
    "            rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "            multiplier += 1\n",
    "        else:\n",
    "            rects = ax.bar(x + offset, measurement, width, label=attribute, bottom=bottom)\n",
    "            bottom += measurement\n",
    "\n",
    "    ax.set_ylabel('Data [Mbit]')\n",
    "    ax.set_xticks(x + width / 2, species)  \n",
    "    ax.set_xticklabels(species, fontsize='small', rotation=45, ha='right')  \n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    y = np.arange(len(species))\n",
    "    width = 0.25  \n",
    "    multiplier = 0\n",
    "    bottom = np.zeros(simulation_time)\n",
    "    fig1, ax1 = plt.subplots()\n",
    "\n",
    "    for attribute, measurement in times.items():\n",
    "        offset = width * multiplier\n",
    "        if attribute == 'Data generated':\n",
    "            rect = ax1.bar(y + offset, measurement, width, label=attribute)\n",
    "            multiplier += 1\n",
    "        else:\n",
    "            rect = ax1.bar(y + offset, measurement, width, label=attribute, bottom=bottom)\n",
    "            bottom += measurement\n",
    "\n",
    "    ax1.set_ylabel('Time [min]')\n",
    "    ax1.set_xticks(y + width / 2, species)  \n",
    "    ax1.set_xticklabels(species, fontsize='small', rotation=45, ha='right')  \n",
    "    ax1.legend(loc='best')\n",
    "    ax1.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "graficarsuma(Walker_01_AOI,Walker_02_AOI,Walker_03_AOI,Walker_04_AOI,Walker_05_AOI,Walker_06_AOI,Walker_07_AOI,Walker_08_AOI,Walker_09_AOI,Walker_10_AOI,\n",
    "                  Walker_01_Svalbard,Walker_02_Svalbard,Walker_03_Svalbard,Walker_04_Svalbard,Walker_05_Svalbard,Walker_06_Svalbard,Walker_07_Svalbard,Walker_08_Svalbard,Walker_09_Svalbard,Walker_10_Svalbard,\n",
    "                  Walker_01_PuntaArenas,Walker_02_PuntaArenas,Walker_03_PuntaArenas,Walker_04_PuntaArenas,Walker_05_PuntaArenas,Walker_06_PuntaArenas,Walker_07_PuntaArenas,Walker_08_PuntaArenas,Walker_09_PuntaArenas,Walker_10_PuntaArenas,\n",
    "                  Walker_01_Cuiaba,Walker_02_Cuiaba,Walker_03_Cuiaba,Walker_04_Cuiaba,Walker_05_Cuiaba,Walker_06_Cuiaba,Walker_07_Cuiaba,Walker_08_Cuiaba,Walker_09_Cuiaba,Walker_10_Cuiaba,\n",
    "                  D_rategenerated,D_ratedown,'Svalbard','PuntaArenas','Cuiaba')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceade0a8",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Valenzuela, A. Q., & Reyes, J. C. G. (2019). Basic Spatial Resolution Metrics for Satellite Imagers. IEEE Sensors Journal, 19(13), 49144922. https://doi.org/10.1109/JSEN.2019.2902512\n",
    "\n",
    "Azami, M. H. bin, Orger, N. C., Schulz, V. H., Oshiro, T., Alarcon, J. R. C., Maskey, A., Nakayama, K., Fukuda, Y., Kojima, K., Yamauchi, T., Masui, H., & Cho, M. (2022). Design and environmental testing of imaging payload for a 6 U CubeSat at low Earth orbit: KITSUNE mission. Frontiers in Space Technologies, 3(November), 116. https://doi.org/10.3389/frspt.2022.1000219"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
